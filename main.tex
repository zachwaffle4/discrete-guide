\documentclass{report}
\usepackage[letterpaper, margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{float}
\usepackage[hidelinks]{hyperref}
\usepackage[T1]{fontenc}
\usepackage{helvet}
\usepackage{amsthm}

\setlength{\parindent}{0pt}
\setcounter{tocdepth}{1}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem*{example}{Example}
\newtheorem*{remark}{Remark}

\numberwithin{theorem}{chapter}
\numberwithin{lemma}{chapter}
\numberwithin{proposition}{chapter}
\numberwithin{corollary}{chapter}
\numberwithin{definition}{chapter}

\DeclarePairedDelimiter{\card}{\lvert}{\rvert}
\DeclarePairedDelimiter{\makeset}{\{}{\}}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\DeclareMathOperator{\prob}{Pr}

\newcommand{\comb}[2]{\operatorname{C}_{#2}^{#1}}
\newcommand{\perm}[2]{\operatorname{P}_{#2}^{#1}}

\newcommand{\powerset}{\mathcal{P}}
\newcommand{\universal}{\mathbb{U}}

\title{A Brief Guide To Discrete Structures}
\author{Zach Harel}

\begin{document}

\maketitle
\tableofcontents

\chapter{Logic}

\section{Propositional Logic}

\begin{definition}
A \textbf{proposition} is a statement that is either true or false.
\end{definition}

\subsection{Basic Logical Operators}

\begin{remark}
Everything in propositional logic can be created using only NOT, AND, and OR.
\end{remark}

\begin{definition}[Negation]
The negation of $p$ (denoted $\neg p$) is true when $p$ is false, and false when $p$ is true.
\end{definition}

\begin{definition}[Conjunction]
$p \land q$ is true only when both $p$ and $q$ are true.
\end{definition}

\begin{definition}[Disjunction]
$p \lor q$ is true when at least one of $p$ or $q$ is true.
\end{definition}

\subsection{More Logical Operators}

\begin{remark}
These operators are commonly used in both mathematics and computer science due to their utility. However, they are simply combinations of the three basic operators.
\end{remark}

\begin{definition}[Implication]
$p \implies q$ is false only when $p$ is true and $q$ is false. We call $p$ the \textbf{hypothesis} (or antecedent) and $q$ the \textbf{conclusion} (or consequent).
\end{definition}

\begin{theorem}
\begin{equation}
p \implies q \equiv \lnot p \lor q
\end{equation}
\end{theorem}

\begin{definition}[Exclusive Disjunction]
$p \oplus q$ is true when either $p$ is true or $q$ is true, but not both.
\end{definition}

\begin{theorem}
\begin{equation}
p \oplus q \equiv (p \lor q) \land \lnot(p \land q)
\end{equation}
\end{theorem}

\subsection{Logical Equivalence}

\begin{definition}
Two propositions are \textbf{logically equivalent} (denoted $\equiv$) if they have the same truth value for all possible truth assignments.
\end{definition}

\begin{remark}
There are many laws of logical equivalence. Here are some commonly used ones.
\end{remark}

\begin{theorem}[De Morgan's Laws]
\begin{align}
\neg(p \land q) &\equiv \neg p \lor \neg q \\
\neg(p \lor q) &\equiv \neg p \land \neg q
\end{align}
\end{theorem}

\begin{theorem}[Double Negation]
\begin{equation}
\neg(\neg p) \equiv p
\end{equation}
\end{theorem}

\begin{theorem}[Contrapositive]
\begin{equation}
(p \implies q) \equiv (\neg q \implies \neg p)
\end{equation}
\end{theorem}

\section{First-Order Logic}

\begin{definition}
First-order logic extends propositional logic with \textbf{predicates} and \textbf{quantifiers}.
\end{definition}

\subsection{Predicates}

\begin{definition}
A \textbf{predicate} is a statement containing variables that becomes a proposition when variables are assigned values.
\end{definition}

\begin{example}
$P(x)$: ``$x$ is even'' becomes a proposition when $x$ is specified.
\end{example}

\subsection{Quantifiers}

\begin{definition}[Universal Quantifier]
$\forall x \, P(x)$ means $P(x)$ is true for every value of $x$ in the domain.
\end{definition}

\begin{definition}[Existential Quantifier]
$\exists x \, P(x)$ means there is at least one value of $x$ in the domain for which $P(x)$ is true.
\end{definition}

\subsection{Negating Quantifiers}

\begin{theorem}
\begin{align}
\neg(\forall x \, P(x)) &\equiv \exists x \, \neg P(x) \\
\neg(\exists x \, P(x)) &\equiv \forall x \, \neg P(x)
\end{align}
\end{theorem}

\subsection{Multiple Quantifiers}

\begin{remark}
Order matters! $\forall x \, \exists y \, P(x, y)$ is different from $\exists y \, \forall x \, P(x, y)$.
\end{remark}

\begin{example}
Let $P(x, y)$: ``$x < y$''
\begin{itemize}
    \item $\forall x \, \exists y \, P(x, y)$: For every number, there exists a larger number (TRUE)
    \item $\exists y \, \forall x \, P(x, y)$: There exists a number larger than all numbers (FALSE)
\end{itemize}
\end{example}

\chapter{Representation of Numbers}

\section{Numeric Bases}

\begin{definition}
A number system with base $b$ uses digits $0$ through $b-1$ to represent values. The rightmost digit represents $b^0$, the next represents $b^1$, and so on.
\end{definition}

\subsection{Common Bases}

\begin{definition}
\begin{itemize}
    \item \textbf{Binary} (base 2): Uses digits 0, 1
    \item \textbf{Octal} (base 8): Uses digits 0-7
    \item \textbf{Decimal} (base 10): Uses digits 0-9
    \item \textbf{Hexadecimal} (base 16): Uses digits 0-9, A-F (where A=10, B=11, ..., F=15)
\end{itemize}
\end{definition}

\subsection{Converting From Base $b$ to Decimal}

\begin{theorem}
To convert a number in base $b$ to decimal, multiply each digit by its positional value and sum:
\begin{equation}
(d_n d_{n-1} \ldots d_1 d_0)_b = d_n \cdot b^n + d_{n-1} \cdot b^{n-1} + \ldots + d_1 \cdot b^1 + d_0 \cdot b^0
\end{equation}
\end{theorem}

\begin{example}
$(1011)_2 = 1 \cdot 2^3 + 0 \cdot 2^2 + 1 \cdot 2^1 + 1 \cdot 2^0 = 8 + 0 + 2 + 1 = (11)_{10}$
\end{example}

\subsection{Converting From Decimal to Base $b$}

\begin{theorem}
Repeatedly divide by $b$ and record remainders from bottom to top.
\end{theorem}

\begin{example}
Convert $(13)_{10}$ to binary:
\begin{align*}
13 \div 2 &= 6 \text{ remainder } 1 \\
6 \div 2 &= 3 \text{ remainder } 0 \\
3 \div 2 &= 1 \text{ remainder } 1 \\
1 \div 2 &= 0 \text{ remainder } 1
\end{align*}
Reading remainders from bottom to top: $(13)_{10} = (1101)_2$
\end{example}

\subsection{Converting Between Non-Decimal Bases}

\begin{theorem}
Convert through decimal as an intermediate step, or use direct conversion for related bases (e.g., binary $\leftrightarrow$ hexadecimal).
\end{theorem}

\begin{theorem}[Binary to Hexadecimal]
Group binary digits in sets of 4 (starting from right), convert each group to its hex equivalent.
\end{theorem}

\begin{example}
$(11010110)_2 = (1101)(0110)_2 = (D6)_{16}$
\end{example}

\section{Signed and Unsigned Numbers}

\subsection{Unsigned Representation}

\begin{definition}
All bits represent magnitude. An $n$-bit unsigned number can represent values from $0$ to $2^n - 1$.
\end{definition}

\begin{example}
With 8 bits, unsigned range is $0$ to $255$.
\end{example}

\subsection{Signed Representation}

\begin{definition}[Sign-Magnitude]
The leftmost bit is the sign bit (0 for positive, 1 for negative), remaining bits represent magnitude.
\end{definition}

\begin{remark}
Problems: Two representations of zero ($+0$ and $-0$), arithmetic is complex.
\end{remark}

\begin{definition}[One's Complement]
Negative numbers are formed by flipping all bits of the positive representation.
\end{definition}

\begin{remark}
Problems: Still has two zeros, arithmetic requires end-around carry.
\end{remark}

\section{Two's Complement}

\begin{definition}
Two's complement is the standard representation for signed integers in modern computers.
\end{definition}

\subsection{Definition}

\begin{definition}
For an $n$-bit number:
\begin{itemize}
    \item If the leftmost bit is 0, the number is positive (same as unsigned)
    \item If the leftmost bit is 1, the number is negative
\end{itemize}

An $n$-bit two's complement number can represent values from $-2^{n-1}$ to $2^{n-1} - 1$.
\end{definition}

\subsection{Converting to Two's Complement}

\begin{theorem}
To represent $-x$ in two's complement:
\begin{enumerate}
    \item Write the binary representation of $x$
    \item Flip all bits (one's complement)
    \item Add 1
\end{enumerate}
\end{theorem}

\begin{example}
Find $-5$ in 8-bit two's complement:
\begin{align*}
5 &= (00000101)_2 \\
\text{Flip bits: } &= (11111010)_2 \\
\text{Add 1: } &= (11111011)_2
\end{align*}

Therefore, $-5 = (11111011)_2$ in 8-bit two's complement.
\end{example}

\subsection{Converting From Two's Complement}

\begin{theorem}
If the leftmost bit is 1 (negative number), apply the same process: flip all bits and add 1.
\end{theorem}

\begin{example}
What is $(11111011)_2$ in decimal?
\begin{align*}
\text{Flip bits: } &= (00000100)_2 \\
\text{Add 1: } &= (00000101)_2 = 5 \\
\text{Since original was negative: } &= -5
\end{align*}
\end{example}

\subsection{Properties of Two's Complement}

\begin{theorem}
Two's complement has the following properties:
\begin{itemize}
    \item Only one representation of zero: $(00\ldots0)_2$
    \item Range for $n$ bits: $-2^{n-1}$ to $2^{n-1} - 1$
    \item The negative of a number equals its two's complement
    \item The leftmost bit has weight $-2^{n-1}$
\end{itemize}
\end{theorem}

\section{Arithmetic in Two's Complement}

\subsection{Addition}

\begin{theorem}
Add numbers normally using binary addition. Discard any carry out of the leftmost bit.
\end{theorem}

\begin{example}
$5 + (-3) = 2$ in 8-bit two's complement:
\begin{align*}
00000101 \text{ (5)} \\
+ \, 11111101 \text{ (-3)} \\
\hline
1\,00000010 \text{ (discard carry, result = 2)}
\end{align*}
\end{example}

\subsection{Subtraction}

\begin{theorem}
To compute $a - b$, add $a$ and the two's complement of $b$: $a + (-b)$.
\end{theorem}

\begin{example}
$7 - 5 = 7 + (-5)$:
\begin{align*}
00000111 \text{ (7)} \\
+ \, 11111011 \text{ (-5)} \\
\hline
1\,00000010 \text{ (result = 2)}
\end{align*}
\end{example}

\subsection{Overflow Detection}

\begin{definition}
Overflow occurs when the result exceeds the representable range.
\end{definition}

\begin{theorem}[Overflow Conditions]
\begin{itemize}
    \item Adding two positive numbers yields a negative result
    \item Adding two negative numbers yields a positive result
    \item Equivalently: carry into the sign bit $\neq$ carry out of the sign bit
\end{itemize}
\end{theorem}

\begin{example}
$127 + 1$ in 8-bit (overflow):
\begin{align*}
01111111 \text{ (127)} \\
+ \, 00000001 \text{ (1)} \\
\hline
10000000 \text{ (-128, overflow!)}
\end{align*}
\end{example}

\subsection{Sign Extension}

\begin{theorem}
To represent an $n$-bit two's complement number with more bits, copy the sign bit into all new leftmost positions.
\end{theorem}

\begin{example}
Extend $(-5)$ from 8-bit to 16-bit:
\begin{align*}
\text{8-bit: } &11111011 \\
\text{16-bit: } &1111111111111011
\end{align*}
\end{example}

\chapter{Sets}

\section{What is a Set?}

\begin{definition}
A set is an unordered collection of unique items.
\end{definition}

\section{Default Sets}

\begin{definition}[Universal Set]
The universal set $\universal$ contains every element in our domain (must be defined for each problem/set of problems).
\end{definition}

\begin{definition}[Empty Set]
The empty set $\varnothing = \makeset{}$ has no elements.
\end{definition}

\section{Set Operations}

\subsection{Equality}

\begin{definition}
Two sets are equal if all of their elements are the same.
\end{definition}

\begin{theorem}
\begin{equation}
(A = B) \iff (\forall x (x \in A \iff x \in B))
\end{equation}
\end{theorem}

\subsection{Cardinality}

\begin{definition}
The cardinality of set $S$ (denoted $\card{S}$) is the number of elements in set $S$.
\end{definition}

\begin{example}
\begin{equation}
\card{\makeset{1, 2, 3}} = 3
\end{equation}
\end{example}

\subsection{Complement}

\begin{definition}
The complement of a set $S$ (denoted $\overline{S}$) is the set of every element (of the universal set) that is not in $S$.
\end{definition}

\begin{example}
If $\universal = \makeset{1, 2, 3, 4, 5}$ and $S = \makeset{1, 4}$, then $\overline{S} = \makeset{2, 3, 5}$.
\end{example}

\begin{theorem}
\begin{equation}
\card{\overline{S}} = \card{\universal} - \card{S}
\end{equation}
\end{theorem}

\subsection{Intersection}

\begin{definition}
The intersection of sets $A$ and $B$ (denoted $A \cap B$) contains every element in both sets.
\end{definition}

\begin{theorem}
\begin{equation}
A \cap B = \{x \mid x \in A \land x \in B\}
\end{equation}
\end{theorem}

\subsection{Union}

\begin{definition}
The union of sets $A$ and $B$ (denoted $A \cup B$) contains every element in either set (with no repeats).
\end{definition}

\begin{theorem}
\begin{align}
A \cup B &= \{x \mid x \in A \lor x \in B\} \\
\card{A \cup B} &= \card{A} + \card{B} - \card{A \cap B}
\end{align}
\end{theorem}

\subsection{Subset}

\begin{definition}
If $A$ is a subset of $B$ (denoted $A \subseteq B$), all elements of $A$ are also elements of $B$.
\end{definition}

\begin{theorem}
\begin{equation}
A \subseteq B \iff \forall x ((x \in A) \implies (x \in B))
\end{equation}
\end{theorem}

\begin{proposition}
Any set is a subset of itself.
\begin{equation}
A \subseteq A
\end{equation}
\end{proposition}

\begin{theorem}
Set equality can be defined using subset:
\begin{equation}
A = B \iff (A \subseteq B) \land (B \subseteq A)
\end{equation}
\end{theorem}

\begin{definition}[Proper Subset]
If $A$ is a proper (or strict) subset of $B$ (denoted $A \subset B$), all elements of $A$ are in $B$, but $A \neq B$.
\end{definition}

\begin{theorem}
\begin{equation}
A \subset B \iff (A \subseteq B) \land (A \neq B)
\end{equation}
\end{theorem}

\begin{definition}
If $A$ is a subset of $B$, then $B$ is a superset of $A$. If $A$ is a proper subset of $B$, then $B$ is a proper superset of $A$.
\end{definition}

\begin{theorem}
\begin{align}
A \subseteq B &\iff B \supseteq A \\
A \subset B &\iff B \supset A
\end{align}
\end{theorem}

\subsection{Difference}

\begin{definition}
The difference of sets $A$ and $B$ (denoted $A - B$) is every element of $A$ that is not in $B$.
\end{definition}

\begin{theorem}
\begin{align}
A - B &= A \cap \overline{B} \\
\card{A - B} &= \card{A \cap \overline{B}}
\end{align}
\end{theorem}

\begin{theorem}
Set difference can be used to define a set's absolute complement:
\begin{equation}
\overline{S} = \universal - S
\end{equation}
\end{theorem}

\begin{definition}
The difference of sets $A$ and $B$ (denoted $A - B$) is sometimes called the relative complement of $B$ with respect to $A$ (denoted $B \backslash A$). The absolute complement of a set $S$ (denoted $\overline{S}$) is its relative complement with respect to the universal set ($\universal \backslash S$).
\end{definition}

\begin{theorem}
\begin{equation}
A - B = A \backslash B
\end{equation}
\end{theorem}

\begin{definition}[Symmetric Difference]
The symmetric difference of sets $A$ and $B$ (denoted $A \Delta B$) is every element of one set that is not in the other set.
\end{definition}

\begin{theorem}
\begin{equation}
A \Delta B = (A - B) \cup (B - A)
\end{equation}
\end{theorem}

\section{Set Functions}

\subsection{Powerset}

\begin{definition}
The powerset of $S$ is the set of all subsets of $S$.
\end{definition}

\begin{theorem}
\begin{equation}
\powerset(S) = \{A \mid A \subseteq S\}
\end{equation}
\end{theorem}

\subsection{Cartesian Product}

\begin{definition}
The Cartesian product of sets $A$ and $B$ is the set of all ordered pairs where the first element is from $A$ and the second is from $B$.
\end{definition}

\begin{theorem}
\begin{equation}
A \times B = \{(a, b) \mid a \in A \land b \in B\}
\end{equation}
\end{theorem}

\begin{definition}
If $A \cap B = \varnothing$, sets $A$ and $B$ are \textbf{disjoint}.
\end{definition}

\chapter{Counting}

\begin{table}[H]
    \centering
    \begin{tabular}{ccc}
         &  No Repetition & Yes Repetition \\
         Order Matters & Permutation $\perm{n}{k}$ & $n^k$ \\
         Order Does Not Matter & Combination $\comb{n}{k}$ & Stars \& Bars \\
    \end{tabular}
    \caption{Which Formula To Use}
    \label{tab:counting}
\end{table}

\section{Counting We've Seen}

\begin{example}
Let $A = \makeset{1, 2, 3}$ and $B = \makeset{3, 4}$. Then:
\begin{equation}
A \times B = \makeset{(1, 3), (1, 4), (2, 3), (2, 4), (3, 3), (3, 4)}
\end{equation}
\end{example}

\begin{theorem}
\begin{equation}
\card{A \times B} = \card{A} \cdot \card{B}
\end{equation}
\end{theorem}

\begin{theorem}
\begin{equation}
\card{\powerset(S)} = 2^{\card{S}}
\end{equation}
\end{theorem}

\section{Product Rule: Order Matters}

\subsection{Two Separate Tasks}

\begin{theorem}[Product Rule]
If one task can be done in $n$ ways and another task can be done in $m$ ways, there are $n \cdot m$ ways to do both tasks.
\end{theorem}

\subsection{Repetition and Permutations}

\begin{remark}
When repetition is okay, we have $k$ tasks and $n$ choices per task; there are $n^k$ ways to do it.

When repetition is not okay, we have $k$ tasks and $n$ choices for the first, $n-1$ for the second, etc. We use permutations for this.
\end{remark}

\begin{definition}
A permutation $\perm{n}{k}$ is an ordering of $k$ objects chosen from $n$ objects.
\end{definition}

\begin{theorem}
\begin{equation}
\perm{n}{k} = \frac{n!}{(n-k)!} \quad \text{and} \quad \perm{n}{n} = n!
\end{equation}
\end{theorem}

\section{Sum Rule: Order Does Not Matter}

\subsection{Two Tasks}

\begin{theorem}[Sum Rule]
If one task can be done in $n$ ways and another task can be done in $m$ ways (mutually exclusive), there are $n + m$ ways to do either task.
\end{theorem}

\subsection{Combinations}

\begin{definition}
A combination $\comb{n}{k}$ is a selection of $k$ objects from $n$ objects where order does not matter.
\end{definition}

\begin{theorem}
\begin{equation}
\comb{n}{k} = \frac{n!}{k!(n-k)!} \quad \text{and} \quad \comb{n}{n} = 1
\end{equation}
\end{theorem}

\subsection{Stars and Bars}

\begin{proposition}
Stars and Bars applies when:
\begin{enumerate}
    \item Order doesn't matter
    \item Repetition is allowed
\end{enumerate}
\end{proposition}

\begin{theorem}[Stars and Bars]
The number of ways to put $n$ indistinguishable objects into $k$ distinguishable bins is:
\begin{equation}
\comb{n + k - 1}{k - 1}
\end{equation}
\end{theorem}

\section{The Pigeonhole Principle}

\begin{theorem}[Pigeonhole Principle]
If there are $n$ objects and $k < n$ boxes, there must be at least one box with $\ceil*{\frac{n}{k}}$ objects in it, where $\ceil{x}$ is the ceiling function (the smallest integer greater than or equal to $x$).
\end{theorem}

\begin{example}
If there are 200 people in a room, at least 17 of them share a birth month, since $\ceil{\frac{200}{12}} = 17$.
\end{example}

\chapter{Probability}

\section{Terms}

\begin{definition}[Experiment]
An infinitely repeatable procedure with a well-defined set of outcomes.
\end{definition}

\begin{definition}[Sample Space]
The sample space $S$ is the set of all possible outcomes of an experiment.
\begin{equation}
S = \makeset{s_1, s_2, s_3, \ldots, s_n}
\end{equation}
\end{definition}

\begin{definition}[Event Space]
An event space $E$ is a subset of outcomes we care about.
\begin{equation}
E \subseteq S
\end{equation}
\end{definition}

\begin{definition}[Probability of Event]
The probability of event $E$ is:
\begin{align}
\prob(E) &= \frac{\card{E}}{\card{S}} \\
\prob(\neg E) &= 1 - \prob(E)
\end{align}
\end{definition}

\begin{remark}
The sample space $S$ is the universal set of events. Although $E$ is treated as a set, the logical not ($\neg$) symbol is used to denote an event \emph{not} occurring.
\end{remark}

\begin{definition}[Expected Value]
An expected value is a numeric value associated with the outcome of an experiment. This is necessary because we can't take the average of non-numeric outcomes like 'pink sock' or 'queen of hearts'.
\end{definition}

\section{Probability of Multiple Events}

\begin{theorem}
Given events $E$ and $F$:
\begin{equation}
\prob(E \cup F) = \prob(E) + \prob(F) - \prob(E \cap F)
\end{equation}
\end{theorem}

\subsection{Independent Events}

\begin{definition}
Two events are independent if the outcome of one doesn't affect the outcome of the other.
\end{definition}

\begin{theorem}
\begin{equation}
\prob(E \cap F) = \prob(E) \cdot \prob(F) \iff \text{$E$ and $F$ are independent}
\end{equation}
\end{theorem}

\begin{remark}
This formula can also be used to determine whether two events are independent.
\end{remark}

\subsection{Conditional Probability}

\begin{definition}
The conditional probability of event $E$ given that event $F$ has already happened is denoted $\prob(E \mid F)$.
\end{definition}

\begin{theorem}
\begin{equation}
\prob(E \mid F) = \frac{\prob(E \cap F)}{\prob(F)}
\end{equation}
\end{theorem}

\begin{theorem}
\begin{equation}
\prob(E \cap F) = \prob(E \mid F) \cdot \prob(F)
\end{equation}
\end{theorem}

\begin{remark}
When calculating $\prob(E \cap F)$, note that $E$ and $F$ are \emph{not} independent, so the formula from Section 5.2 does not apply.
\end{remark}

\subsection{Bayes' Theorem}

\begin{theorem}[Bayes' Theorem]
\begin{equation}
\prob(E \mid F) = \frac{\prob(F \mid E) \cdot \prob(E)}{\prob(F)}
\end{equation}
\end{theorem}

\subsection{General Insights}

\begin{theorem}[Law of Total Probability]
Given that $\prob(F) = \prob(F \cap E) + \prob(F \cap \neg E)$ and Theorem 5.8:
\begin{equation}
\prob(F) = \prob(F \mid E) \cdot \prob(E) + \prob(F \mid \neg E) \cdot \prob(\neg E)
\end{equation}
\end{theorem}

\section{Expectations}

\subsection{Expected Values}

\begin{definition}
The expected value of a random variable is:
\begin{equation}
E[X] = \sum_{s_i \in S} \prob(s_i) \cdot X_i
\end{equation}

This is essentially a weighted average of each outcome times the value of that outcome.
\end{definition}

\subsection{Linearity of Expectations}

\begin{theorem}[Linearity of Expectation]
\begin{equation}
E(X_1 + X_2 + \cdots + X_n) = E[X_1] + E[X_2] + \cdots + E[X_n]
\end{equation}
\end{theorem}

\begin{example}
To find the expected number of heads in 100 coin flips, use linearity of expectation: each flip has expected value $\frac{1}{2}$, so 100 flips have expected value $100 \cdot \frac{1}{2} = 50$.
\end{example}

\chapter{Sequences and Series}

\begin{definition}
A sequence is an ordered list of potentially an infinite number of numbers.
\end{definition}

\begin{definition}
A sequence is defined as $\{a_n\} = a_1, a_2, a_3, \ldots, a_n$. An infinite sequence is also defined as a mapping from $\mathbb{Z}^+$ to $\{a_n\}$.
\end{definition}

\subsection{Notation}

\begin{remark}
\begin{itemize}
    \item $a_n$: denotes either the whole sequence or the final term
    \item $a_k$: denotes any one arbitrary term
\end{itemize}
\end{remark}

\section{Forms}

\subsection{Recursive Form}

\begin{definition}[Recursive Sequence]
A sequence defined recursively uses the previous term to define the next term.
\end{definition}

\begin{theorem}[Arithmetic Sequence - Recursive]
\begin{equation}
a_k = a_{k-1} + d
\end{equation}
where $d$ is the common difference.
\end{theorem}

\begin{theorem}[Geometric Sequence - Recursive]
\begin{equation}
a_k = r \cdot a_{k-1}
\end{equation}
where $r$ is the common ratio.
\end{theorem}

\subsection{Closed Form}

\begin{definition}[Closed Form Sequence]
A closed form sequence does not depend on any other term.
\end{definition}

\begin{theorem}[Arithmetic Sequence - Closed Form]
\begin{equation}
a_k = a_1 + (k-1)d
\end{equation}
\end{theorem}

\begin{theorem}[Geometric Sequence - Closed Form]
\begin{equation}
a_k = a_1 \cdot r^{k-1}
\end{equation}
\end{theorem}

\begin{example}
Consider the sequence $\{a_n\}$ where $a_k = \frac{k}{k+1}$ for all $n \in \mathbb{Z}^+$.

Then $a_1 = \frac{1}{2}$, $a_2 = \frac{2}{3}$, and $a_{512} = \frac{512}{513}$.
\end{example}

\begin{example}
Consider the sequence $\{b_n\}$ where $b_k = (-1)^k$ for all $n \in \mathbb{Z}^+$.

Then $b_1 = -1$, $b_2 = 1$, and $b_{124} = 1$.
\end{example}

\section{Specific Series}

\subsection{Arithmetic Series}

\begin{theorem}[Arithmetic Series]
For any arithmetic series with first term $a_1$ and common difference $d$, the sum of the first $n$ terms is:
\begin{equation}
\sum_{k=1}^{n} a_k = \frac{n(a_1 + a_n)}{2}
\end{equation}
\end{theorem}

\subsection{Geometric Series}

\begin{theorem}[Geometric Series]
For any geometric series with first term $a_1$ and common ratio $r$, the sum of the first $n$ terms is:
\begin{equation}
\sum_{k=1}^{n} a_k = \frac{a_1(r^n - 1)}{r - 1}
\end{equation}
\end{theorem}

\section{Summation Rules}

\begin{theorem}[Constant Summation]
\begin{equation}
\sum_{i=1}^{n} k = nk
\end{equation}
where $k \in \mathbb{R}$.
\end{theorem}

\begin{theorem}[Constant Multiplication]
\begin{equation}
\sum_{i=1}^{n} k \cdot a_i = k \sum_{i=1}^{n} a_i
\end{equation}
where $k \in \mathbb{R}$ and $a_i$ is the $i$th term of a sequence $\{a_n\}$.
\end{theorem}

\begin{theorem}[Summation Bounds]
\begin{equation}
\sum_{i=a}^{n} s_i = \sum_{i=1}^{n} s_i - \sum_{i=1}^{a-1} s_i
\end{equation}
where $a \in \mathbb{N}$ and $s_i$ is the $i$th term of a sequence $\{s_n\}$.
\end{theorem}

\begin{theorem}[Summation Addition]
\begin{equation}
\sum_{i=1}^{n} (a_i + b_i) = \sum_{i=1}^{n} a_i + \sum_{i=1}^{n} b_i
\end{equation}
where $a_i$ and $b_i$ are the $i$th terms of sequences $\{a_n\}$ and $\{b_n\}$ respectively.
\end{theorem}

\chapter{Mathematical Induction}

\begin{definition}
Proof by induction is a technique used in mathematics and computer science to prove that a predicate $P(n)$ holds for all positive integers $n$.
\end{definition}

\section{Structure}

A proof by induction has the following major components:

\subsection{Predicate and Logic Statement}

\begin{definition}
The first part is the predicate, which is usually an equation or statement that may or may not be true for any given value of its inputs.
\end{definition}

\begin{example}
\begin{itemize}
    \item $\displaystyle P(n): \sum_{i=1}^{n} i = \frac{n(n+1)}{2}$
    \item $P(n): 6^n + 4$ is a multiple of 5
\end{itemize}
\end{example}

\begin{remark}
We then create a logic statement so that we can actually prove it:
\begin{equation}
\forall n \in \mathbb{Z}^+, P(n)
\end{equation}
\end{remark}

\subsection{Inductive Hypothesis and Implication}

\begin{definition}
To prove the logic statement, we prove the implication $P(k) \implies P(k+1)$ and assume $P(k)$ is true. That assumption is called the inductive hypothesis.
\end{definition}

\subsection{Base Case}

\begin{definition}
The base case is a proof for the smallest value of $n$ that we want to prove. The inductive cases will follow it.
\end{definition}

\subsection{Inductive Step}

\begin{definition}
After assuming $P(k)$ is true and proving $P(n)$ for the smallest value of $n$, we use the inductive hypothesis to prove $P(k+1)$.
\end{definition}

\section{Example: Integer Summations}

\begin{theorem}
\begin{equation}
\sum_{i=1}^{n} i = \frac{n(n+1)}{2}
\end{equation}
\end{theorem}

\begin{proof}
We prove by mathematical induction that $\displaystyle \sum_{i=1}^{n} i = \frac{n(n+1)}{2}$ for all $n \in \mathbb{Z}^+$.

\textbf{Base case:} For $n = 1$:
\begin{equation}
\sum_{i=1}^{1} i = 1 = \frac{(1)(1+1)}{2} = \frac{2}{2}
\end{equation}
The base case holds.

\textbf{Inductive step:} Assume the inductive hypothesis that for some $k \in \mathbb{Z}^+$:
\begin{equation}
\sum_{i=1}^{k} i = \frac{k(k+1)}{2}
\end{equation}

We must show:
\begin{equation}
\sum_{i=1}^{k+1} i = \frac{(k+1)(k+2)}{2}
\end{equation}

Starting with the left-hand side:
\begin{align*}
\sum_{i=1}^{k+1} i &= \sum_{i=1}^{k} i + (k+1) \\
&= \frac{k(k+1)}{2} + (k+1) \quad \text{(by inductive hypothesis)} \\
&= \frac{k(k+1)}{2} + \frac{2(k+1)}{2} \\
&= \frac{k(k+1) + 2(k+1)}{2} \\
&= \frac{(k+1)(k+2)}{2}
\end{align*}

By mathematical induction, the theorem holds for all positive integers $n$.
\end{proof}

\end{document}