\documentclass{report}
\usepackage[letterpaper, margin=1in]{geometry}
\usepackage{graphicx} % Required for inserting images
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{float}
\usepackage[hidelinks]{hyperref}

\setlength{\parindent}{0pt}

\setcounter{tocdepth}{1}

\DeclarePairedDelimiter{\card}{\lvert}{\rvert}
\DeclarePairedDelimiter{\makeset}{\{}{\}}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\DeclareMathOperator{\comb}{C}
\DeclareMathOperator{\perm}{P}
\DeclareMathOperator{\prob}{Pr}

\newcommand{\powerset}{\mathcal{P}}
\newcommand{\universal}{\mathbb{U}}

\title{A Brief Guide To Discrete Structures}
\author{Zach Harel}

\begin{document}

\maketitle

\tableofcontents

\chapter{Logic}

\section{Propositional Logic}

A \textbf{proposition} is a statement that is either true or false.

\subsection{Basic Logical Operators}

Everything in propositional logic can be created using only NOT, AND, and OR.

\subsubsection{$\neg$: Negation (NOT)}
The negation of $p$ ($\neg p$) is true when $p$ is false, and false when $p$ is true.

\subsubsection{$\land$: Conjunction (AND)}
$p \land q$ is true only when both $p$ and $q$ are true.

\subsubsection{$\lor$: Disjunction (OR)}
$p \lor q$ is true when at least one of $p$ or $q$ is true.

\subsection{More Logical Operators}

These operators are commonly used in both mathematics and computer science due to their utility. However, they are simply combinations of the three basic operators.

\subsubsection{$\implies$: Implication (IF-THEN)}
$p \implies q$ is false only when $p$ is true and $q$ is false.

\begin{itemize}
    \item $p$ is the \textbf{hypothesis} (or antecedent)
    \item $q$ is the \textbf{conclusion} (or consequent)
\end{itemize}

\begin{equation}
    p \implies q \equiv \lnot p \lor q
\end{equation}

\subsubsection{$\oplus$: Exclusive Disjunction (XOR)}

$p \oplus q$ is true when either $p$ is true or $q$ is true, but not both.

\begin{equation}
    p \oplus q \equiv (p \lor q) \land \lnot(p \land q)
\end{equation}

\subsection{Logical Equivalence}

Two propositions are \textbf{logically equivalent} ($\equiv$) if they have the same truth value for all possible truth assignments.

There are many laws of logical equivalence; you can Google them, but here are some commonly used ones.

\subsubsection{De Morgan's Laws}
\begin{align}
    \neg(p \land q) &\equiv \neg p \lor \neg q \\
    \neg(p \lor q) &\equiv \neg p \land \neg q
\end{align}

\subsubsection{Double Negation}
\begin{equation}
    \neg(\neg p) \equiv p
\end{equation}

\subsubsection{Contrapositive}
\begin{equation}
    (p \implies q) \equiv (\neg q \implies \neg p)
\end{equation}

\section{First-Order Logic}

First-order logic extends propositional logic with \textbf{predicates} and \textbf{quantifiers}.

\subsection{Predicates}

A \textbf{predicate} is a statement containing variables that becomes a proposition when variables are assigned values.

Example: $P(x)$: ``$x$ is even'' becomes a proposition when $x$ is specified.

\subsection{Quantifiers}

\subsubsection{$\forall$: Universal Quantifier (FOR ALL)}
$\forall x \, P(x)$ means $P(x)$ is true for every value of $x$ in the domain.

\subsubsection{$\exists$: Existential Quantifier (THERE EXISTS)}
$\exists x \, P(x)$ means there is at least one value of $x$ in the domain for which $P(x)$ is true.

\subsection{Negating Quantifiers}

\begin{align}
    \neg(\forall x \, P(x)) &\equiv \exists x \, \neg P(x) \\
    \neg(\exists x \, P(x)) &\equiv \forall x \, \neg P(x)
\end{align}

\subsection{Multiple Quantifiers}

Order matters! $\forall x \, \exists y \, P(x, y)$ is different from $\exists y \, \forall x \, P(x, y)$.

Example: Let $P(x, y)$: ``$x < y$''
\begin{itemize}
    \item $\forall x \, \exists y \, P(x, y)$: For every number, there exists a larger number (TRUE)
    \item $\exists y \, \forall x \, P(x, y)$: There exists a number larger than all numbers (FALSE)
\end{itemize}

\chapter{Representation of Numbers}

\section{Numeric Bases}

A number system with base $b$ uses digits $0$ through $b-1$ to represent values. The rightmost digit represents $b^0$, the next represents $b^1$, and so on.

\subsection{Common Bases}

\begin{itemize}
    \item \textbf{Binary} (base 2): Uses digits 0, 1
    \item \textbf{Octal} (base 8): Uses digits 0-7
    \item \textbf{Decimal} (base 10): Uses digits 0-9
    \item \textbf{Hexadecimal} (base 16): Uses digits 0-9, A-F (where A=10, B=11, ..., F=15)
\end{itemize}

\subsection{Converting From Base $b$ to Decimal}

To convert a number in base $b$ to decimal, multiply each digit by its positional value and sum.

\begin{equation}
    (d_n d_{n-1} \ldots d_1 d_0)_b = d_n \cdot b^n + d_{n-1} \cdot b^{n-1} + \ldots + d_1 \cdot b^1 + d_0 \cdot b^0
\end{equation}

\textbf{Example:} $(1011)_2 = 1 \cdot 2^3 + 0 \cdot 2^2 + 1 \cdot 2^1 + 1 \cdot 2^0 = 8 + 0 + 2 + 1 = (11)_{10}$

\subsection{Converting From Decimal to Base $b$}

Repeatedly divide by $b$ and record remainders from bottom to top.

\textbf{Example:} Convert $(13)_{10}$ to binary:
\begin{align*}
    13 \div 2 &= 6 \text{ remainder } 1 \\
    6 \div 2 &= 3 \text{ remainder } 0 \\
    3 \div 2 &= 1 \text{ remainder } 1 \\
    1 \div 2 &= 0 \text{ remainder } 1
\end{align*}

Reading remainders from bottom to top: $(13)_{10} = (1101)_2$

\subsection{Converting Between Non-Decimal Bases}

Convert through decimal as an intermediate step, or use direct conversion for related bases (e.g., binary $\leftrightarrow$ hexadecimal).

\textbf{Binary to Hexadecimal:} Group binary digits in sets of 4 (starting from right), convert each group to its hex equivalent.

\textbf{Example:} $(11010110)_2 = (1101)(0110)_2 = (D6)_{16}$

\section{Signed and Unsigned Numbers}

\subsection{Unsigned Representation}

All bits represent magnitude. An $n$-bit unsigned number can represent values from $0$ to $2^n - 1$.

\textbf{Example:} With 8 bits, unsigned range is $0$ to $255$.

\subsection{Signed Representation}

Multiple methods exist to represent signed integers:

\subsubsection{Sign-Magnitude}

The leftmost bit is the sign bit (0 for positive, 1 for negative), remaining bits represent magnitude.

\textbf{Problems:} Two representations of zero ($+0$ and $-0$), arithmetic is complex.

\subsubsection{One's Complement}

Negative numbers are formed by flipping all bits of the positive representation.

\textbf{Problems:} Still has two zeros, arithmetic requires end-around carry.

\section{Two's Complement}

Two's complement is the standard representation for signed integers in modern computers.

\subsection{Definition}

For an $n$-bit number:
\begin{itemize}
    \item If the leftmost bit is 0, the number is positive (same as unsigned)
    \item If the leftmost bit is 1, the number is negative
\end{itemize}

An $n$-bit two's complement number can represent values from $-2^{n-1}$ to $2^{n-1} - 1$.

\subsection{Converting to Two's Complement}

To represent $-x$ in two's complement:
\begin{enumerate}
    \item Write the binary representation of $x$
    \item Flip all bits (one's complement)
    \item Add 1
\end{enumerate}

\textbf{Example:} Find $-5$ in 8-bit two's complement:
\begin{align*}
    5 &= (00000101)_2 \\
    \text{Flip bits: } &= (11111010)_2 \\
    \text{Add 1: } &= (11111011)_2
\end{align*}

Therefore, $-5 = (11111011)_2$ in 8-bit two's complement.

\subsection{Converting From Two's Complement}

If the leftmost bit is 1 (negative number), apply the same process: flip all bits and add 1.

\textbf{Example:} What is $(11111011)_2$ in decimal?
\begin{align*}
    \text{Flip bits: } &= (00000100)_2 \\
    \text{Add 1: } &= (00000101)_2 = 5 \\
    \text{Since original was negative: } &= -5
\end{align*}

\subsection{Properties of Two's Complement}

\begin{itemize}
    \item Only one representation of zero: $(00...0)_2$
    \item Range for $n$ bits: $-2^{n-1}$ to $2^{n-1} - 1$
    \item The negative of a number equals its two's complement
    \item The leftmost bit has weight $-2^{n-1}$
\end{itemize}

\section{Arithmetic in Two's Complement}

\subsection{Addition}

Add numbers normally using binary addition. Discard any carry out of the leftmost bit.

\textbf{Example:} $5 + (-3) = 2$ in 8-bit two's complement:
\begin{align*}
    00000101 \text{ (5)} \\
    + \, 11111101 \text{ (-3)} \\
    \hline
    1\,00000010 \text{ (discard carry, result = 2)}
\end{align*}

\subsection{Subtraction}

To compute $a - b$, add $a$ and the two's complement of $b$: $a + (-b)$.

\textbf{Example:} $7 - 5 = 7 + (-5)$:
\begin{align*}
    00000111 \text{ (7)} \\
    + \, 11111011 \text{ (-5)} \\
    \hline
    1\,00000010 \text{ (result = 2)}
\end{align*}

\subsection{Overflow Detection}

Overflow occurs when the result exceeds the representable range.

\textbf{Overflow conditions:}
\begin{itemize}
    \item Adding two positive numbers yields a negative result
    \item Adding two negative numbers yields a positive result
    \item Equivalent: carry into the sign bit $\neq$ carry out of the sign bit
\end{itemize}

\textbf{Example:} $127 + 1$ in 8-bit (overflow):
\begin{align*}
    01111111 \text{ (127)} \\
    + \, 00000001 \text{ (1)} \\
    \hline
    10000000 \text{ (-128, overflow!)}
\end{align*}

\subsection{Sign Extension}

To represent an $n$-bit two's complement number with more bits, copy the sign bit into all new leftmost positions.

\textbf{Example:} Extend $(-5)$ from 8-bit to 16-bit:
\begin{align*}
    \text{8-bit: } &11111011 \\
    \text{16-bit: } &1111111111111011
\end{align*}

\chapter{Sets}

\section{What is a Set?}

A set is simply an unordered collection of unique items.

\section{Default Sets}

\subsection{$\universal$: The Universal Set}
Contains every element in our domain (must be defined for each problem/set of problems).

\subsection{$\varnothing$: The Empty Set} 
\{\}; Has no elements.

\section{Set Operations}

\subsection{=: Equality}

Two sets are equal if all of their elements are the same.

\begin{equation}
    (A = B) \iff (\forall x (x \in A \iff x \in B))
\end{equation}

\subsection{$\card{S}$: Cardinality}

The cardinality of set $S$ ($\vert S \vert$) is the number of elements in set $S$.

\begin{equation}
    \card{\makeset{1, 2, 3}} = 3
\end{equation}

\subsection{$\overline{S}$: Complement}

The complement of a set $S$ ($\overline{S}$) is the set of every element (of the universal set) that is not in $S$.

For example, if $\universal = \makeset{1, 2, 3, 4, 5}$ and $S = \makeset{1, 4}$, $\overline{S} = \makeset{2, 3, 5}$.

\begin{equation}
    \vert \overline{S} \vert = \vert \universal \vert - \vert S \vert
\end{equation}

\subsection{$\cap$: Intersection}

The intersection of sets $A$ and $B$ ($A \cap B$) contains every element in both sets.

\begin{equation}
    A \cap B = \{x | x \in A \land x \in B\} 
\end{equation}

\subsection{$\cup$: Union}

The union of sets $A$ and $B$ ($A \cup B$) contains every element in either set (with no repeats).

\begin{align}
    A \cup B &= \{x \vert x \in A \lor x \in B\} \\
    \card{A \cup B} &= \card{A} + \card{B} + \card{A \cap B}
\end{align}

\subsection{$\subseteq$: Subset}

If $A$ is a subset of $B$ ($A \subseteq B$), all elements of $A$ are also elements of $B$.

\begin{equation}
    A \subseteq B \iff \forall x (x \in A) \implies (x \in B)
\end{equation}

Any set is a subset of itself.

\begin{equation}
    A \subseteq A
\end{equation}

The subset definition can also be used to define set equality.

\begin{equation}
    A = B \iff (A \subseteq B) \land (B \subseteq A)
\end{equation}

If $A$ is a \emph{proper} (also called strict) subset of $B$ ($A \subset B)$,
all elements of $A$ are in $B$, but $A$ is not $B$.

\begin{equation}
    A \subset B \iff (A \subseteq B) \land (A  \not= B)
\end{equation}

If $A$ is a subset of $B$, $B$ is a superset of $A$; if $A$ is a proper subset of $B$, $B$ is a proper superset of $A$.

\begin{align}
    A \subseteq B &\iff B \supseteq A \\
    A \subset B &\iff B \supset A
\end{align}

\subsection{$-$: Difference}

The difference of sets $A$ and $B$ ($A$ - $B$) is every element of $A$ that is not in $B$.

\begin{align}
    A - B &= A \cap \overline{B} \\
    \card{A - B} &= \card{A \cap \overline{B}}
\end{align}

Set difference can also be used to define a set's absolute complement (the previously defined complement):

\begin{equation}
    \overline{S} = \universal - S
\end{equation}

The difference of sets $A$ and $B$ ($A - B$) is sometimes called the relative complement of B with respect to A ($B \backslash A$). The absolute complement of a set $S$  ($\overline{S}) $is simply its relative complement with respect to the universal set ($\universal \backslash {S}$).

\begin{equation}
    A - B = A \backslash B
\end{equation}

The \emph{symmetric} difference of sets $A$ and $B$ ($A \Delta B)$ is every element of one set that is not in the other set.

\begin{equation}
    A \Delta B = (A - B) \cup (B - A)
\end{equation}

\section{Set Functions}

\subsection{Powerset}
\begin{itemize}
    \item input: set
    \item output: set of sets
\end{itemize}

\begin{equation}
    \powerset(S) = \{A \vert A \subseteq S\}
\end{equation}

\subsection{Cartesian Product}
\begin{itemize}
    \item input: two sets
    \item output: set of ordered pairs
\end{itemize}

\begin{equation}
    A \times B = \{(a, b) | a \in A \wedge b \in B \}
\end{equation}

If $A \cap B = \varnothing$, $A$ and $B$ are \textbf{disjoint}.

\chapter{Counting}

\begin{table}[H]
    \centering
    \begin{tabular}{ccc}
         &  No Repetition& Yes Repetition\\
         Order Matters &  Permutation $\perm(n, k)$& $n^k$\\
         Order Does Not Matter &  Combination $\comb(n, k)$ & Stars \& Bars\\
    \end{tabular}
    \caption{Which Formula To Use}
    \label{tab:placeholder}
\end{table}

\section{Counting We've Seen}

\begin{align*}
    \text{let } A &= \makeset{1, 2, 3} \text{ and } B = \makeset{3, 4}
    \\ &\therefore \\
    A \times B &= \makeset{(1, 3), (1, 4), (2, 3), (2, 4), (3, 3), (3, 4)}
\end{align*}


\begin{equation}
    \card{A \times B} = \card{A} \cdot \card{B}
\end{equation}

\begin{equation}
    \card{\powerset(S)} = 2^{\card{S}}
\end{equation}

\section{Product Rule: Order Matters}

\subsection{Two Separate Tasks}
\begin{itemize}
    \item one task in $n$ ways
    \item one task in $m$ ways
\end{itemize}

\begin{equation}
    \text{There are } n \cdot m \text{ ways to do task 1 \textbf{and} task 2.}
\end{equation}

\subsection{One Task Multiple Ways}
When repetition is okay, we have $k$ tasks and $n$ choices per task; there are $n^k$ ways to do it.

When repetition is not okay, we have $k$ tasks and $n$ choices for the first task, $n-1$ for the second task, etc. For this, we use permutations: $\perm(n, k)$.

\begin{align}
    \text{$\perm(n, k)$} &= \text{$k$ permutations of $n$ objects is an ordering of $k$ of the objects.} \\
    \perm(n, k) &= \frac{n!}{(n-k)!} \text{; } \perm(n, n) = n!
\end{align}

\section{Sum Rule: Order Does Not Matter}

\subsection{Two Tasks}
\begin{itemize}
    \item one task in $n$ ways
    \item one task in $m$ ways
\end{itemize}

\begin{equation}
    \text{There are } n + m \text{ ways to do task 1 \textbf{or} task 2.}
\end{equation}

\subsection{One Task Multiple Ways}
When repetition is okay, see the Stars and Bars subsection!

When repetition is not okay, we have $k$ tasks and $n$ choices for the first task, $n-1$ for the second task, etc. For this, we use combinations: $\comb(n, k)$.

\begin{align}
    \text{$\comb(n, k)$} &= \text{$k$ combinations of $n$ objects is a set of $k$ of the objects.} \\
    \comb(n, k) &= \frac{n!}{k!(n-k)!} \text{; } \comb(n, n) = 1
\end{align}

\subsection{Stars and Bars}

\begin{enumerate}
    \item Order doesn't matter
    \item Repetition is allowed
\end{enumerate}

How many ways are there to put $n$ indistinguishable balls into $n$ distinguishable bins?

This is secretly a combination problem! 

\begin{align}
    n_{\text{combination}} &= n_{\text{stars and bars}} + k_{\text{stars and bars}} + 1 \\
    k_{\text{combination}} &= k_{\text{stars and bars}} -1
\end{align}

This means that the answer to our initial question is simply
$\comb(n + k + 1, k - 1)!$

\section{The Pigeonhole Principle}

The bridge between Counting and Probability!
We are putting objects in boxes. 

This principle starts with the idea that you have a bunch of pigeons, and a bunch of pigeonholes, and every pigeon must go into a pigeonhole. If there are more pigeons than pigeonholes, then you are guaranteed  that at least one pigeonhole contains at least 2 pigeons. This is the closest I could get to drawing pigeons; there are 6 pigeonholes in the drawings below and 7 pigeons. 

If there are 200 people in a room, it is guaranteed that at least 17 of them share a birth month. It is not guaranteed (it is likely) that even one person was born in October (or any other month, for that matter). 

In more general terms, the Pigeonhole Principle states that, if you have $n$ objects and $k < n$ boxes, there must be at least one box with $\ceil{\frac{n}{k}}$ \footnote{$\ceil{x}$ aka ceil($x$) is the smallest integer that is greater than $x$. Eg $\ceil{2.5} = \ceil{2.9} = \ceil{2.00001} = 3$.} objects in it.

\begin{equation}
    \text{Given $n$ objects and $k$ boxes, at least one box has } \ceil*{\frac{n}{k}} \text{ objects in it.}
\end{equation}


\chapter{Probability}

\section{Terms}

\subsubsection{Experiment}

An infinitely repeatable procedure with a well-defined set of outcomes.

\subsubsection{Sample Space $S$}

All possible outcomes of an experiment.

\begin{equation}
    S = \makeset{s_1, s_2, s_3, ... s_n}
\end{equation}

\subsubsection{Event Space $E$}

Subset of outcomes we care about.

\begin{equation}
    E \subseteq S
\end{equation}

\subsubsection{Probability of Event $E$}

How likely event $E$ is to occur.

\begin{align}
    \prob(E) &= \frac{\card{E}}{\card{S}} \\
    \prob(\lnot{E}) &= \frac{\card{\overline{E}}}{\card{S}} = 1 - \prob(E)
\end{align}

The RHS of equation 5.4 works because the sample space $S$ is the universal set of events. Note that despite treating $E$ like a set, the logical not ($\lnot$) symbol is used to mark an event \emph{not} occurring.

\subsubsection{Expected Value $x$}

A numeric value associated with the outcome of the experiment. Used because we can't take the average of 'pink sock' or 'queen of hearts'.

\section{Probability of Multiple Events}

A generalization of the product rule and sum rule.

Given events $E$ and $F$:

\begin{equation}
    \prob(E \cup F) = \prob(E) + \prob(F) + \prob(E \cap F)
\end{equation}

\subsection{Independent Events}

Two events are independent if the outcome of one doesn't affect the outcome of the other.

\begin{equation}
    \prob(E \cap F) = \prob(E) \cdot \prob(F) \iff \text{$E$ and $F$ are independent}
\end{equation}

In addition to determining the probability of two events that we \emph{know} are independent, we can also use that formula to determine \emph{if} two events are independent.

\subsection{Conditional Probability}

The likelihood of an event $E$ occurring,  given that another event $F$ has already happened. The probability of $E$ given $F$ is written as $\prob(E | F)$.

\begin{equation}
    \prob(E | F) = \frac{\prob(E \cap F)}{\prob(F)}
\end{equation}

Note that when calculating $\prob(E \cap F)$, $E$ and $F$ are \emph{not} independent; formula 5.6 does not apply. However, we can arrange that equation to find that

\begin{equation}
    \prob(E \cap F) = \prob(E | F) \cdot \prob(F)
\end{equation}

\subsection{Bayes' Theorem}

Bayes' theorem states

\begin{equation}
    \prob(E | F) = \frac{\prob(F | E) \cdot \prob(E)}{\prob(F)}
\end{equation}

\subsection{General Insights}

Given that $\prob(F) = \prob(F \cap E) + \prob(F \cap \lnot{E})$ and what was discovered in equation 5.8, we can find that

\begin{equation}
    \prob(F) = \prob(F | E) \cdot \prob(E) + \prob(F | \lnot{E}) \cdot \prob(\lnot{E})
\end{equation}

\section{Expectations}

\subsection{Expected Values}

After running an experiment over and over...

\subsubsection{On average, what happens?}

\begin{equation}
    E[x] = \sum_{s_i \in S}{\prob(s_i) \cdot x_i}
\end{equation}

It is essentially a weighted average of each outcome times the value of that outcome.

\subsection{Linearity of Expectations}

What if we wanted to know the number of heads if we flip a coin 100 times?

\begin{equation}
    E(x_1 + x_2 + \cdots + x_n) = E[x_1] + E[x_2] + \cdots + E[x_n]
\end{equation}

\chapter{Sequences and Series}

A sequence is a discrete structure used to discover and characterize patterns (such as earthquakes, comets, and the stock market).

\begin{quote}
    A sequence is an ordered list of potentially an infinite number of numbers.
\end{quote}

\section{Definition}

A sequence is defined like $\makeset{a_n} = a_1, a_2, a_3, \cdots, a_n$. If the sequence is infinite, there is no $n$th term. \medskip

An infinite sequence is also defined as a mapping from $\mathbb{Z}^+$ to $\makeset{a_n}$.

\subsection{Notation}
\begin{itemize}
    \item $a_n$: the whole sequence or the final term
    \item $a_k$: any one arbitrary term
\end{itemize}

\subsection{Forms}

\subsubsection{Recursive Form}

A sequence can be defined recursively, using the previous term. \medskip

An arithmetic sequence can be defined recursively like this:

\begin{equation}
    a_k = a_{k-1} + \beta
\end{equation}

A geometric sequence can be defined recursively like this:

\begin{equation}
    a_k = \beta \cdot a_{k-1}
\end{equation}

\subsubsection{Closed Form}

A closed form sequence does not depend on any other term. \medskip

An arithmetic sequence can be defined explicitly like this:

\begin{equation}
    a_k = \beta \cdot k
\end{equation}

A geometric sequence can be defined recursively like this:

\begin{equation}
    a_k = \beta^k
\end{equation}

Of course, other types of sequences exist, such as:

\begin{equation*}
    {a_n} \forall n \in \mathbb{Z}^+ a_k = \frac{k}{k+1}
\end{equation*}

With this sequence, $a_1 = \frac{1}{2}$, $a_2 = \frac{2}{3}$, and $a_{512} = \frac{512}{513}$. \medskip

And

\begin{equation*}
    {b_n} \forall n \in \mathbb{Z}^+ b_k = (-1)^k
\end{equation*}

With this sequence, $b_1 = -1$, $b_2 = 1$, and $b_{124} = 1$.

\section{Specific Series}

\subsection{Arithmetic Series}

For any arithmetic series $a_k = a + (k-1)d$, the sum of the first $n$ terms is

\begin{equation}
    \sum_{k=1}^{n}{a_k} = \frac{n(a_1 \cdot a_n)}{2}
\end{equation}

\subsection{Geometric Series}

For any geometric series $a_k = a \cdotp r^{k-1}$, the sum of the first $n$ terms is

\begin{equation}
    \sum_{k=1}^{n}{a_k} = \frac{a_1 \cdotp r^n - a_1}{r-1}
\end{equation}

\section{Summation Rules}

\subsubsection{Constant Summation}

\begin{equation}
    \sum_{i=1}^{n}{k} = nk
\end{equation}

where $k \in \mathbb{R}$

\subsubsection{Constant Multiplication}

\begin{equation}
    \sum_{i=1}^{n} a_i = k \sum_{i=1}^{n} a_i
\end{equation}

where $k \in \mathbb{R}$ and $a_i$ is the $i$th term of a sequence $\{a_n\}$.

\subsubsection{Summation Bounds}

\begin{equation}
    \sum_{i=a}^{n} s_i = \sum_{i=1}^{n} s_i + \sum_{i=1}^{a-1} s_i
\end{equation}

where $a \in \mathbb{N}$ and $s_i$ is the $i$th term of a sequence $\{s_n\}$.

\subsubsection{Summation Addition}

\begin{equation}
    \sum_{i=1}^{n} a_i + b_i = \sum_{i=1}^{n} a_i + \sum_{i=1}^{n} b_i
\end{equation}

where $a_i$ and $b_i$ are the $i$th term of sequences $\{a_n\}$ and $\{b_n\}$ respectively.

\end{document}
